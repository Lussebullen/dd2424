{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and prepare text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"goblet_book.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "book_chars = list(set(data))\n",
    "K = len(book_chars)\n",
    "\n",
    "charToInd = {c:i for i,c in enumerate(book_chars)}\n",
    "indToChar = {i:c for i,c in enumerate(book_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toString(encoded_text):\n",
    "    return ''.join([indToChar[i] for i in encoded_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(x):\n",
    "    Y = np.zeros((K, len(x)))\n",
    "    for i,c in enumerate(x):\n",
    "        Y[charToInd[c],i] = 1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN():\n",
    "    def __init__(self, K, m=100, seed=123456789):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.sigma = 0.01\n",
    "\n",
    "        self.weights = {}\n",
    "        self.momentum = {}\n",
    "        \n",
    "        # Biases\n",
    "        self.weights[\"b\"] = np.zeros(shape=(self.m,1))\n",
    "        self.weights[\"c\"] = np.zeros(shape=(K,1))\n",
    "\n",
    "        # Weights\n",
    "        self.weights[\"U\"] = np.random.randn(self.m, self.K) * self.sigma\n",
    "        self.weights[\"W\"] = np.random.randn(self.m, self.m) * self.sigma\n",
    "        self.weights[\"V\"] = np.random.randn(self.K, self.m) * self.sigma\n",
    "\n",
    "        # Momentum\n",
    "        for key, value in self.weights.items():\n",
    "            self.momentum[key] = np.zeros(value.shape)\n",
    "\n",
    "        # Set initial hidden state\n",
    "        self.hprev = np.zeros(shape=(self.m,1))\n",
    "    \n",
    "    def cost(self, X, Y):\n",
    "        P = self.forward(X)\n",
    "\n",
    "        loss = -np.sum(Y * np.log(P))\n",
    "        return loss\n",
    "    \n",
    "    def forward(self, X, train=False):\n",
    "\n",
    "        hList = [self.hprev.copy()]\n",
    "        aList = []\n",
    "        oList = []\n",
    "        pList = []\n",
    "\n",
    "        for x in X.T:\n",
    "            a = self.weights[\"W\"] @ hList[-1] + self.weights[\"U\"] @ x.reshape(-1,1) + self.weights[\"b\"]\n",
    "            h = np.tanh(a)\n",
    "            o = self.weights[\"V\"] @ h + self.weights[\"c\"]\n",
    "            p = np.exp(o) / np.sum(np.exp(o), axis=0)\n",
    "\n",
    "            hList.append(h)\n",
    "            aList.append(a)\n",
    "            oList.append(o)\n",
    "            pList.append(p)\n",
    "\n",
    "            H = np.hstack(hList)\n",
    "            A = np.hstack(aList)\n",
    "            O = np.hstack(oList)\n",
    "            P = np.hstack(pList)\n",
    "        \n",
    "        if train:\n",
    "            self.hprev = H[:, -1].reshape(-1,1)\n",
    "            # P: K x seq_length, H: m x seq_length+1, A: m x seq_length, O: K x seq_length\n",
    "            return P, H, A, O\n",
    "        else:\n",
    "            return P\n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "            \n",
    "            P, H, A, O = self.forward(X, train=True)\n",
    "    \n",
    "            g = P - Y #gradO\n",
    "            gV = g @ H.T[1:]\n",
    "            gc = np.sum(g, axis = 1).reshape(-1,1)\n",
    "    \n",
    "            gH = g.T[-1] @ self.weights[\"V\"]\n",
    "            gA = gH * (1 - np.square(np.tanh(A.T[-1])))\n",
    "\n",
    "            lH = [gH]\n",
    "            lA = [gA]\n",
    "    \n",
    "            # Page 42\n",
    "            for gt, at in zip(g.T[-2::-1], A.T[-2::-1]):\n",
    "                gH = gt @ self.weights[\"V\"] + gA @ self.weights[\"W\"]\n",
    "                gA = gH * (1 - np.square(np.tanh(at)))\n",
    "\n",
    "                lH.append(gH)\n",
    "                lA.append(gA)\n",
    "\n",
    "            gH = np.vstack(lH[::-1]).T\n",
    "            gA = np.vstack(lA[::-1]).T\n",
    "\n",
    "            gW = gA @ H.T[:-1]\n",
    "            gU = gA @ X.T\n",
    "            gb = np.sum(gA, axis = 1).reshape(-1,1)\n",
    "\n",
    "            return {\"W\":gW, \"U\":gU, \"V\":gV, \"b\":gb, \"c\":gc}\n",
    "\n",
    "    \n",
    "    def synth(self, x0, n):\n",
    "\n",
    "        h = self.hprev\n",
    "        x = x0\n",
    "\n",
    "        for i in range(n):\n",
    "            a = self.weights[\"W\"] @ h + self.weights[\"U\"] @ x[:,-1].reshape(-1,1) + self.weights[\"b\"]\n",
    "            h = np.tanh(a)\n",
    "            o = self.weights[\"V\"] @ h + self.weights[\"c\"]\n",
    "            p = np.exp(o) / np.sum(np.exp(o), axis=0)\n",
    "            idx = np.random.choice(range(self.K),p=np.squeeze(p))\n",
    "            newX = np.zeros(shape=(self.K,1))\n",
    "            newX[idx,0] = 1\n",
    "            x = np.c_[x,newX]\n",
    "        \n",
    "        return [np.argmax(c) for c in x.T]\n",
    "    \n",
    "    def computeGradsNumerical(self, X, Y, eps):\n",
    "        grads = {}\n",
    "        for name, weight in self.weights.items():\n",
    "            shape = weight.shape\n",
    "            w_perturb = np.zeros(shape)\n",
    "            w_gradsNum = np.zeros(shape)\n",
    "            w_0 = weight.copy()\n",
    "            \n",
    "            for i in range(shape[0]):\n",
    "                for j in range(shape[1]):\n",
    "\n",
    "                    # add perturbation\n",
    "                    w_perturb[i, j] = eps\n",
    "                    \n",
    "                    # compute perturbation 1 cost\n",
    "                    w_tmp = w_0 - w_perturb\n",
    "                    self.weights[name] = w_tmp\n",
    "                    cost1 = self.cost(X, Y)\n",
    "                \n",
    "                    # compute perturbation 2 cost\n",
    "                    w_tmp = w_0 + w_perturb\n",
    "                    self.weights[name] = w_tmp\n",
    "                    cost2 = self.cost(X, Y)\n",
    "                    lossDiff = (cost2 - cost1) / (2 * eps)\n",
    "                    \n",
    "                    w_gradsNum[i, j] = lossDiff\n",
    "                    w_perturb[i, j] = 0\n",
    "        \n",
    "            grads[name] = w_gradsNum\n",
    "            \n",
    "            # reset\n",
    "            self.weights[name] = w_0\n",
    "            \n",
    "        return grads\n",
    "        \n",
    "    def train(self, X, Y, eta=0.1):\n",
    "        eps = 1e-8\n",
    "        grads = self.backward(X, Y)\n",
    "\n",
    "        for key, weight in grads.items():\n",
    "\n",
    "            # Clip as per instructions\n",
    "            grads[key] = np.clip(grads[key], -5, 5)\n",
    "\n",
    "            self.momentum[key] += np.square(grads[key])\n",
    "            \n",
    "            weight = weight - eta * grads[key] / np.sqrt(self.momentum[key] + eps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "eta = 0.1\n",
    "seq_length = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = oneHotEncode([\"a\"])\n",
    "model = RNN(K, m=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aT1m)HsbHS,ju2YwT)hT\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toString(model.synth(x, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relerr(ga, gn, eps=1e-6):\n",
    "        \"\"\"\n",
    "        Calculates the relative error between two vectors.\n",
    "\n",
    "        Args:\n",
    "            ga (numpy.ndarray): Analytical gradient.\n",
    "            gn (numpy.ndarray): Numerical gradient.\n",
    "            eps (float, optional): A small value to avoid division by zero. Defaults to 1e-6.\n",
    "\n",
    "        Returns:\n",
    "            float: The relative error between ga and gn.\n",
    "        \"\"\"\n",
    "        \n",
    "        diff = np.linalg.norm(ga - gn)\n",
    "        norma = np.linalg.norm(ga)\n",
    "        normn = np.linalg.norm(gn)\n",
    "        numer = max(eps, norma + normn)\n",
    "        return diff / numer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xchars = data[0:seq_length]\n",
    "Ychars = data[1:seq_length+1]\n",
    "\n",
    "X = oneHotEncode(Xchars) # K x seq_length\n",
    "Y = oneHotEncode(Ychars) # K x seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, H, A, O = model.forward(X, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 25), (5, 26), (5, 25), (80, 25))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape, H.shape, A.shape, O.shape\n",
    "# P: K x seq_length, H: m x seq_length+1, A: m x seq_length, O: K x seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical sanity check\n",
    "\n",
    "for m=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "1.4813157496523907e-09\n",
      "c\n",
      "3.202869557764459e-10\n",
      "U\n",
      "2.8914449842650106e-09\n",
      "W\n",
      "7.481230399723106e-08\n",
      "V\n",
      "3.586694094579524e-09\n"
     ]
    }
   ],
   "source": [
    "angrads = model.backward(X, Y)\n",
    "numgrads = model.computeGradsNumerical(X, Y, 1e-4)\n",
    "for key in numgrads.keys():\n",
    "    print(key)\n",
    "    print(relerr(angrads[key], numgrads[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.5 - Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Epoch 0 ====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0\n",
      "HARRY POTTER AND THE GOBLA9Tq\t6\n",
      "3\n",
      "FC4\"?'IC\"XD?T!;-mOZnB?07:_7JS!ep\n",
      "?(s.(3t3:03eü0dD/K6_BH4xVyOV3N;wEGdee)au(•l!JIojLXAg9730uI90F;BQ?Frh!iUh2\t\n",
      "lZfü.CKoj!PAwHJ:PIvl\")H)•4eM76ZH)Zx/;I-s9B^dtr!9COP•ZOM!\timDJ/•hfDKM/3c:R:?h•t\thTSG\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m X \u001b[38;5;241m=\u001b[39m oneHotEncode(Xchars) \u001b[38;5;66;03m# K x seq_length\u001b[39;00m\n\u001b[1;32m     31\u001b[0m Y \u001b[38;5;241m=\u001b[39m oneHotEncode(Ychars) \u001b[38;5;66;03m# K x seq_length\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcost(X,Y)\n\u001b[1;32m     36\u001b[0m lossSmooth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.999\u001b[39m\u001b[38;5;241m*\u001b[39mlossSmooth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.001\u001b[39m\u001b[38;5;241m*\u001b[39mloss\n",
      "Cell \u001b[0;32mIn[5], line 150\u001b[0m, in \u001b[0;36mRNN.train\u001b[0;34m(self, X, Y, eta)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[1;32m    149\u001b[0m     eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-8\u001b[39m\n\u001b[0;32m--> 150\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, weight \u001b[38;5;129;01min\u001b[39;00m grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m         \u001b[38;5;66;03m# Clip as per instructions\u001b[39;00m\n\u001b[1;32m    155\u001b[0m         grads[key] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(grads[key], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 66\u001b[0m, in \u001b[0;36mRNN.backward\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m---> 66\u001b[0m         P, H, A, O \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m         g \u001b[38;5;241m=\u001b[39m P \u001b[38;5;241m-\u001b[39m Y \u001b[38;5;66;03m#gradO\u001b[39;00m\n\u001b[1;32m     69\u001b[0m         gV \u001b[38;5;241m=\u001b[39m g \u001b[38;5;241m@\u001b[39m H\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m1\u001b[39m:]\n",
      "Cell \u001b[0;32mIn[5], line 42\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, X, train)\u001b[0m\n\u001b[1;32m     39\u001b[0m pList \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mT:\n\u001b[0;32m---> 42\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m@\u001b[39m hList[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m@\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m     h \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtanh(a)\n\u001b[1;32m     44\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m@\u001b[39m h \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = 100\n",
    "eta = 0.1\n",
    "seq_length = 25\n",
    "model = RNN(K, m=m)\n",
    "dataSetSize = len(data)\n",
    "\n",
    "# Epoch Counter\n",
    "epoch = 0\n",
    "\n",
    "# Text position counter\n",
    "e = 0\n",
    "\n",
    "# Initialize smooth loss\n",
    "Xchars = data[0:seq_length]\n",
    "Ychars = data[1:seq_length+1]\n",
    "X = oneHotEncode(Xchars) # K x seq_length\n",
    "Y = oneHotEncode(Ychars) # K x seq_length\n",
    "lossSmooth = model.cost(X,Y)\n",
    "\n",
    "lossHistory = []\n",
    "lossBest = lossSmooth\n",
    "weightBest = model.weights.copy()\n",
    "iterCount = 0\n",
    "\n",
    "print(f\"==== Epoch {0} ====\")\n",
    "while epoch < 5:\n",
    "    Xchars = data[e:e+seq_length]\n",
    "    Ychars = data[e+1:e+seq_length+1]\n",
    "\n",
    "    X = oneHotEncode(Xchars) # K x seq_length\n",
    "    Y = oneHotEncode(Ychars) # K x seq_length\n",
    "\n",
    "    model.train(X, Y, eta=0.1)\n",
    "\n",
    "    loss = model.cost(X,Y)\n",
    "    lossSmooth = 0.999*lossSmooth + 0.001*loss\n",
    "\n",
    "    # Checkpoint when loss is improved\n",
    "    if lossSmooth < lossBest:\n",
    "        weightsBest = model.weights.copy()\n",
    "        lossBest = lossSmooth\n",
    "    \n",
    "    # Log loss every 100 steps\n",
    "    if iterCount % 100 == 0:\n",
    "        lossHistory.append(lossSmooth)\n",
    "\n",
    "    # Synth 200 chars of text every 1000 steps\n",
    "    if iterCount % 1000 == 0:\n",
    "        txtenc = model.synth(X, 200)\n",
    "\n",
    "        txt = \"\".join([indToChar[ind] for ind in txtenc])\n",
    "        print(\"Step: \", iterCount)\n",
    "        print(txt)\n",
    "\n",
    "    e += seq_length\n",
    "    iterCount += 1\n",
    "\n",
    "    if e + seq_length >= dataSetSize:\n",
    "        e = 0\n",
    "        epoch += 1\n",
    "        print(f\"==== Epoch {epoch} ====\")\n",
    "        model.hprev = np.zeros(shape=(m,1))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
