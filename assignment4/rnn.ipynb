{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and prepare text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"goblet_book.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "book_chars = list(set(data))\n",
    "K = len(book_chars)\n",
    "\n",
    "charToInd = {c:i for i,c in enumerate(book_chars)}\n",
    "indToChar = {i:c for i,c in enumerate(book_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toString(encoded_text):\n",
    "    return ''.join([indToChar[i] for i in encoded_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(x):\n",
    "    Y = np.zeros((K, len(x)))\n",
    "    for i,c in enumerate(x):\n",
    "        Y[charToInd[c],i] = 1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN():\n",
    "    def __init__(self, K, m=100, seed=123456789):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.sigma = 0.01\n",
    "\n",
    "        self.weights = {}\n",
    "        self.momentum = {}\n",
    "        \n",
    "        # Biases\n",
    "        self.weights[\"b\"] = np.zeros(shape=(self.m,1))\n",
    "        self.weights[\"c\"] = np.zeros(shape=(K,1))\n",
    "\n",
    "        # Weights\n",
    "        self.weights[\"U\"] = np.random.randn(self.m, self.K) * self.sigma\n",
    "        self.weights[\"W\"] = np.random.randn(self.m, self.m) * self.sigma\n",
    "        self.weights[\"V\"] = np.random.randn(self.K, self.m) * self.sigma\n",
    "\n",
    "        # Momentum\n",
    "        for key, value in self.weights.items():\n",
    "            self.momentum[key] = np.zeros(value.shape)\n",
    "\n",
    "        # Set initial hidden state\n",
    "        self.h0 = np.zeros(shape=(self.m,1))\n",
    "    \n",
    "    def cost(self, X, Y):\n",
    "        P = self.forward(X)\n",
    "\n",
    "        loss = -np.sum(Y * np.log(P))\n",
    "        return loss\n",
    "    \n",
    "    def forward(self, X, train=False):\n",
    "\n",
    "        hList = [self.h0.copy()]\n",
    "        aList = []\n",
    "        oList = []\n",
    "        pList = []\n",
    "\n",
    "        for x in X.T:\n",
    "            a = self.weights[\"W\"] @ hList[-1] + self.weights[\"U\"] @ x.reshape(-1,1) + self.weights[\"b\"]\n",
    "            h = np.tanh(a)\n",
    "            o = self.weights[\"V\"] @ h + self.weights[\"c\"]\n",
    "            p = np.exp(o) / np.sum(np.exp(o), axis=0)\n",
    "\n",
    "            hList.append(h)\n",
    "            aList.append(a)\n",
    "            oList.append(o)\n",
    "            pList.append(p)\n",
    "\n",
    "            H = np.hstack(hList)\n",
    "            A = np.hstack(aList)\n",
    "            O = np.hstack(oList)\n",
    "            P = np.hstack(pList)\n",
    "        \n",
    "        if train:\n",
    "            self.h0 = H[:, -1].reshape(-1,1)\n",
    "            # P: K x seq_length, H: m x seq_length+1, A: m x seq_length, O: K x seq_length\n",
    "            return P, H, A, O\n",
    "        else:\n",
    "            return P\n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "            \n",
    "            P, H, A, O = self.forward(X, train=True)\n",
    "    \n",
    "            g = P - Y #gradO\n",
    "            gV = g @ H.T[1:]\n",
    "            gc = np.sum(g, axis = 1).reshape(-1,1)\n",
    "    \n",
    "            gH = g.T[-1] @ self.weights[\"V\"]\n",
    "            gA = gH * (1 - np.square(np.tanh(A.T[-1])))\n",
    "\n",
    "            lH = [gH]\n",
    "            lA = [gA]\n",
    "    \n",
    "            # Page 42\n",
    "            for gt, at in zip(g.T[-2::-1], A.T[-2::-1]):\n",
    "                gH = gt @ self.weights[\"V\"] + gA @ self.weights[\"W\"]\n",
    "                gA = gH * (1 - np.square(np.tanh(at)))\n",
    "\n",
    "                lH.append(gH)\n",
    "                lA.append(gA)\n",
    "\n",
    "            gH = np.vstack(lH[::-1]).T\n",
    "            gA = np.vstack(lA[::-1]).T\n",
    "\n",
    "            gW = gA @ H.T[:-1]\n",
    "            gU = gA @ X.T\n",
    "            gb = np.sum(gA, axis = 1).reshape(-1,1)\n",
    "\n",
    "            return {\"W\":gW, \"U\":gU, \"V\":gV, \"b\":gb, \"c\":gc}\n",
    "\n",
    "    \n",
    "    def synth(self, x0, n):\n",
    "\n",
    "        h = self.h0\n",
    "        x = x0\n",
    "\n",
    "        for i in range(n):\n",
    "            a = self.weights[\"W\"] @ h + self.weights[\"U\"] @ x[:,-1].reshape(-1,1) + self.weights[\"b\"]\n",
    "            h = np.tanh(a)\n",
    "            o = self.weights[\"V\"] @ h + self.weights[\"c\"]\n",
    "            p = np.exp(o) / np.sum(np.exp(o), axis=0)\n",
    "            idx = np.random.choice(range(self.K),p=np.squeeze(p))\n",
    "            newX = np.zeros(shape=(self.K,1))\n",
    "            newX[idx,0] = 1\n",
    "            x = np.c_[x,newX]\n",
    "        \n",
    "        return [np.argmax(c) for c in x.T]\n",
    "    \n",
    "    def computeGradsNumerical(self, X, Y, eps):\n",
    "        grads = {}\n",
    "        for name, weight in self.weights.items():\n",
    "            shape = weight.shape\n",
    "            w_perturb = np.zeros(shape)\n",
    "            w_gradsNum = np.zeros(shape)\n",
    "            w_0 = weight.copy()\n",
    "            \n",
    "            for i in range(shape[0]):\n",
    "                for j in range(shape[1]):\n",
    "\n",
    "                    # add perturbation\n",
    "                    w_perturb[i, j] = eps\n",
    "                    \n",
    "                    # perturb weight vector negatively\n",
    "                    # and compute cost\n",
    "                    w_tmp = w_0 - w_perturb\n",
    "                    self.weights[name] = w_tmp\n",
    "                    cost1 = self.cost(X, Y)\n",
    "                \n",
    "                    # perturb weight vector positively\n",
    "                    # and compute cost\n",
    "                    w_tmp = w_0 + w_perturb\n",
    "                    self.weights[name] = w_tmp\n",
    "                    cost2 = self.cost(X, Y)\n",
    "                    lossDiff = (cost2 - cost1) / (2 * eps)\n",
    "                    \n",
    "                    # get numerical grad f. W[i, j]\n",
    "                    w_gradsNum[i, j] = lossDiff\n",
    "                    w_perturb[i, j] = 0\n",
    "        \n",
    "            # save grads\n",
    "            grads[name] = w_gradsNum\n",
    "            \n",
    "            # reset\n",
    "            self.weights[name] = w_0\n",
    "            \n",
    "        return grads\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "eta = 0.1\n",
    "seq_length = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = oneHotEncode([\"a\"])\n",
    "model = RNN(K, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a:N\\nyerF4FY,^•d u,•wl'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toString(model.synth(x, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relerr(ga, gn, eps=1e-6):\n",
    "        \"\"\"\n",
    "        Calculates the relative error between two vectors.\n",
    "\n",
    "        Args:\n",
    "            ga (numpy.ndarray): Analytical gradient.\n",
    "            gn (numpy.ndarray): Numerical gradient.\n",
    "            eps (float, optional): A small value to avoid division by zero. Defaults to 1e-6.\n",
    "\n",
    "        Returns:\n",
    "            float: The relative error between ga and gn.\n",
    "        \"\"\"\n",
    "        \n",
    "        diff = np.linalg.norm(ga - gn)\n",
    "        norma = np.linalg.norm(ga)\n",
    "        normn = np.linalg.norm(gn)\n",
    "        numer = max(eps, norma + normn)\n",
    "        return diff / numer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xchars = data[0:seq_length]\n",
    "Ychars = data[1:seq_length+1]\n",
    "\n",
    "X = oneHotEncode(Xchars) # K x seq_length\n",
    "Y = oneHotEncode(Ychars) # K x seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, H, A, O = model.forward(X, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 25), (100, 26), (100, 25), (80, 25))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape, H.shape, A.shape, O.shape\n",
    "# P: K x seq_length, H: m x seq_length+1, A: m x seq_length, O: K x seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "angrads = model.backward(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "numgrads = model.computeGradsNumerical(X, Y, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "4.522574447354954e-09\n",
      "c\n",
      "4.0230462054063615e-10\n",
      "U\n",
      "2.2198521028447137e-08\n",
      "W\n",
      "6.180653160583247e-07\n",
      "V\n",
      "5.86874726731972e-08\n"
     ]
    }
   ],
   "source": [
    "for key in numgrads.keys():\n",
    "    print(key)\n",
    "    print(relerr(angrads[key], numgrads[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
